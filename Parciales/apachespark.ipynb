{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "try: \n",
    "    type(sc)\n",
    "except NameError:\n",
    "    sc = pyspark.SparkContext('local[*]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primer Cuatrimestre de 2017. Examen parcial, primera oportunidad.\n",
    "\n",
    "Se tiene información estadística de la temporada regular de todos los\n",
    "jugadores de la NBA en un RDD de tuplas con el siguiente formato:\n",
    "(id_jugador, nombre, promedio_puntos, promedio_asistencias, promedio_robos,\n",
    "promedio_bloqueos, promedio_rebotes, promedio_faltas). \n",
    "\n",
    "Un analista de la\n",
    "cadena ESPN está trabajando con un RDD que corresponde a la primera ronda\n",
    "de playoffs y que tiene el siguiente formato: (id_jugador, id_partido, timestamp,\n",
    "cantidad_puntos, cantidad_rebotes, cantidad_bloqueos, cantidad_robos,\n",
    "cantidad_asistencias, cantidad_faltas). \n",
    "\n",
    "<b>En base a estos RDDs se quiere\n",
    "programar en PySpark un programa que genere un RDD con los nombres (sin\n",
    "duplicados) de los jugadores que lograron en algún partido de playoffs una\n",
    "cantidad de asistencias mayor a su promedio histórico.</b> (****) (15 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# usamos para simplificar el formato, que puede obtenerse con un map.\n",
    "# (id_jugador, nombre, promedio_asistencias)\n",
    "players_all_time_stats = [\n",
    "    (1, 'Manu Ginobili', 800),\n",
    "    (2, 'Kobe Bryant', 100),\n",
    "    (3, 'Marc Gasol', 25),\n",
    "    (4, 'James Harden', 1000)]\n",
    "\n",
    "# usamos para simplificar el formato, que puede obtenerse con un map.\n",
    "# (id_jugador, id_partido, timestamp, cantidad_asistencias)\n",
    "scores = [\n",
    "  (1, 1, 1, 100),\n",
    "  (1, 1, 3, 100),\n",
    "  (2, 1, 1, 150),\n",
    "  (2, 1, 3, 150),\n",
    "  (3, 2, 2, 50),\n",
    "  (3, 2, 3, 50),      \n",
    "  (1, 2, 1, 150),\n",
    "  (1, 2, 3, 150),\n",
    "]\n",
    "\n",
    "players_all_time_stats_rdd = sc.parallelize(players_all_time_stats)\n",
    "scores_rdd = sc.parallelize(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 150), (2, 150), (3, 50), (1, 100)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_season = rdd_scores.map(lambda x: ((x[0],x[1]),x[3])).map(lambda a: (a[0][0], a[1])).distinct()\n",
    "stats_season.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, ('Manu Ginobili', 800)),\n",
       " (2, ('Kobe Bryant', 100)),\n",
       " (3, ('Marc Gasol', 25)),\n",
       " (4, ('James Harden', 1000))]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_players = players_all_time_stats_rdd.map(lambda x: (x[0],(x[1],x[2])))\n",
    "info_players.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, (150, ('Manu Ginobili', 800))),\n",
       " (1, (100, ('Manu Ginobili', 800))),\n",
       " (2, (150, ('Kobe Bryant', 100))),\n",
       " (3, (50, ('Marc Gasol', 25)))]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = stats_season.join(info_players)\n",
    "stats.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kobe Bryant', 'Marc Gasol']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.filter(lambda x: x[1][0] > x[1][1][1]).map(lambda x: x[1][1][0]).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parcial 2016 2do Cuatrimestre. Examen parcial, segunda oportunidad.\n",
    "\n",
    "En este ejercicio queremos programar un sistema que recomiende\n",
    "textos a usuarios en base a sus gustos sobre ciertos términos (palabras).\n",
    "\n",
    "Se cuenta con un RDD de textos de la forma (docId, texto) donde texto\n",
    "es un string de longitud variable. \n",
    "\n",
    "Además contamos con un RDD que\n",
    "indica qué términos le gustan o no a cada usuario de la forma (userId,\n",
    "término, score) por ejemplo (23, “calesita”, -2). \n",
    "\n",
    "Se pide programar en Spark un programa que calcule el score total de cada documento para cada usuario generando un RDD de la forma (userId, docId, score) en donde el score es simplemente la suma de los scores del usuario para\n",
    "los términos que aparecen en el documento. \n",
    "\n",
    "Puede haber términos en los documentos para los cuales no exista score de algunos usuarios, en\n",
    "estos casos simplemente los consideramos neutros (score=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = [\n",
    "    (1, 'pablo honey'),\n",
    "    (2, 'the bends'),\n",
    "    (3, 'ok computer'),\n",
    "    (4, 'kid a'),\n",
    "    (5, 'amnesiac'),\n",
    "    (6, 'hail to the thief'),\n",
    "    (7, 'in rainbows'),\n",
    "    (8, 'the king of limbs'),\n",
    "    (9, 'a moon shaped pool')\n",
    "]\n",
    "\n",
    "scores = [\n",
    "    ('thom', 'pablo', 1),\n",
    "    ('thom', 'honey', 1),\n",
    "    ('martin', 'pablo', -1),\n",
    "    ('martin', 'honey', -1),\n",
    "    ('martin', 'ok', 30),\n",
    "    ('martin', 'computer', 30)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd_documents = sc.parallelize(documents,4)\n",
    "rdd_scores = sc.parallelize(scores,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words_by_documents_rdd = rdd_documents.flatMap(lambda x: [(word,x[0]) for word in x[1].split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores_for_join_rdd = rdd_scores.map(lambda x: (x[1],(x[0],x[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('thom', 1, 2), ('martin', 1, -2), ('martin', 3, 60)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ('pablo', (1,('thom', 1))\n",
    "words_by_documents_rdd.join(scores_for_join_rdd).map(lambda x: ((x[1][1][0], x[1][0]), x[1][1][1]))\\\n",
    "    .reduceByKey(lambda x,y: x+y).map(lambda x: (x[0][0],x[0][1],x[1])).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2015-02 2do Recuperatorio\n",
    "Un telescopio registra automaticamente la luminosidad de distintas\n",
    "estrellas generando un RDD con registros de tipo (star_id,\n",
    "magnitude,spectral_type, timestamp). Queremos obtener un listado de\n",
    "estrellas que tienen el mismo tipo espectral e igual promedio de\n",
    "magnitud una vez redondeado el mismo a un decimal. El resultado\n",
    "debe ser una lista en donde cada elemento de la lista es una lista de ids\n",
    "de estrellas similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stars = [\n",
    "    (1, 5, 1, 1),\n",
    "    (2, 10, 1, 1),\n",
    "    (3, 6, 1, 1),\n",
    "    (4, 5.5, 2, 1),\n",
    "    (1, 6, 1, 2),\n",
    "    (2, 9, 1, 2),\n",
    "    (3, 5, 1, 2),\n",
    "    (1, 5.5, 1, 3),\n",
    "    (2, 11, 1, 3),\n",
    "    (3, 5.5, 1, 3)\n",
    "]\n",
    "rdd = sc.parallelize(stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((1, 5.5), [1, 3]), ((1, 10.0), [2]), ((2, 5.5), [4])]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.map(lambda x: ((x[0], x[2]), (x[1], 1)))\\\n",
    "    .reduceByKey(lambda x, y: (x[0]+y[0], x[1]+y[1]))\\\n",
    "    .map(lambda x: ((x[0][1], round(x[1][0]/x[1][1],1)), x[0][0]))\\\n",
    "    .groupByKey()\\\n",
    "    .map(lambda x: (x[0], list(x[1])))\\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Organización de Datos 75.06. Segundo Cuatrimestre de 2015. Examen parcial, segunda oportunidad:\n",
    "1) Se tiene un RDD con libros en donde cada registro es un texto. Se\n",
    "pide obtener todos los anagramas de mas de 7 letras que puedan\n",
    "encontrarse. El formato de salida debe ser una lista de listas en donde\n",
    "cada lista tiene un conjunto de palabras que son anagramas. Ejemplo:\n",
    "[[discounter,introduces,reductions],[percussion,supersonic]...]\n",
    " (4*) (15 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['percussion', 'supersonic'], ['discounter', 'reductions', 'introduces']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = ['the discounter reductions',\n",
    "        'the air introduces supersonic sounds',\n",
    "        'anana no es lo misma que naana',\n",
    "        'percussion and fourious introduces panic']\n",
    "\n",
    "rdd = sc.parallelize(texts)\n",
    "rdd.flatMap(lambda x: x.split()).filter(lambda x: len(x)>=7).distinct()\\\n",
    ".map(lambda x: (''.join(sorted(x)),x)).groupByKey().map(lambda x: list(x[1])).filter(lambda x: len(x)>1).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
