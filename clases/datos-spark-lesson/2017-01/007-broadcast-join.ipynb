{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "try: \n",
    "    type(sc)\n",
    "except NameError:\n",
    "    sc = pyspark.SparkContext('local[*]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Broadcast Join (map-side join)\n",
    "\n",
    "## Variable Broadcast\n",
    "\n",
    "Una variable Broadcast nos permite mantener una variable solo lectura cacheada en cada una de las maquinas del cluster en vez de enviar esa informacion con cada una de las tareas que se envian al cluster.\n",
    "\n",
    "Esto es particularmente util cuando cuando tareas a partir de multiples etapas (stages) necesitan la misma informacion o cuando cachear informacion de forma deserealizada es importante.\n",
    "\n",
    "Tener en cuenta que esto **es posible** cuando uno de los data sets o conjunto de datos **es lo suficientemente pequeÃ±o para ser broadcasteado a todos los nodos/workers del cluster**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Vamos a suponer que tenemos un RDD de productos por sus IDs identificando ventas de los mismos\n",
    "prodsList = [1,11,1,4,5,11,2,3,4,5,6,4,5,4,3,2,1,11,2,3,4,5,6,4,3,2,1,1]\n",
    "prods = sc.parallelize(prodsList,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Un hash con los productos y sus nombres\n",
    "productNames = {1:'papas',\n",
    "                2:'cebollas',\n",
    "                3:'tomates',\n",
    "                4:'zanahorias',\n",
    "                5:'batatas',\n",
    "                6:'peras',\n",
    "                7:'cilantro',\n",
    "                8:'apio',\n",
    "                9:'morrones',\n",
    "                10:'manzanas',\n",
    "                11:'naranjas'}\n",
    "\n",
    "#hacemos un broadcast de la variable\n",
    "bproductNames = sc.broadcast(productNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 4), (1, 5), (4, 6), (2, 4), (5, 4)]\n"
     ]
    }
   ],
   "source": [
    "# Buscamos los productos que se vendieron mas de 4 veces\n",
    "popularProds = prods.map(lambda x:(x,1)).reduceByKey(lambda x,y:x+y).filter(lambda x:x[1]>=4)\n",
    "print popularProds.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Realizand un map-side join\n",
    "\n",
    "El join se realiza de forma implicita usando un map y dentro del mismo accediendo a la informacion de la variable a la que se realizo el broadcast via ```.value```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('tomates', 3, 4), ('papas', 1, 5), ('zanahorias', 4, 6), ('cebollas', 2, 4), ('batatas', 5, 4)]\n"
     ]
    }
   ],
   "source": [
    "# Buscamos los nombres\n",
    "# map side-join\n",
    "# a partir del broadcast la informacion de los nombres de los productos fueron distribuidos\n",
    "# a los nodos en el cluster y son consultados en el map (haciendo el join implicito)\n",
    "popularProds = popularProds.map(lambda x:(bproductNames.value[x[0]],x[0],x[1]))\n",
    "print popularProds.collect()                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Ventajas\n",
    "\n",
    "Cuando un valor es broadcasted al cluster, este es copiado a los nodos/workers **solo una vez** (en vez de multiples veces si la informacion fuera a enviarse en cada task). De esta forma se hara que la aplicacion sea mas rapida. \n",
    "\n",
    "\n",
    "### Algunas referencias extras interesantes\n",
    "- [https://spark.apache.org/docs/latest/programming-guide.html#broadcast-variables](https://spark.apache.org/docs/latest/programming-guide.html#broadcast-variables)\n",
    "- [http://dmtolpeko.com/2015/02/20/map-side-join-in-spark/](http://dmtolpeko.com/2015/02/20/map-side-join-in-spark/)\n",
    "- [https://jaceklaskowski.gitbooks.io/mastering-apache-spark/content/spark-broadcast.html](https://jaceklaskowski.gitbooks.io/mastering-apache-spark/content/spark-broadcast.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
