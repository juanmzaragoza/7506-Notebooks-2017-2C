{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRADIANCE GUIA 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "try: \n",
    "    type(sc)\n",
    "except NameError:\n",
    "    sc = pyspark.SparkContext('local[*]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Archivo.txt:\n",
    "    \n",
    "    datos spark guia\n",
    "    spark hadoop \n",
    "    guia datos spark gradience\n",
    "\n",
    "    Corremos:\n",
    "\n",
    "    sc.textFile(\"Archivo.txt\") .flatMap(lambda a: a.split()) .map(lambda a: (a, 1)) .reduceByKey(lambda a, b: a+b) .takeOrdered(3, key = lambda x: -x[1])\n",
    "    \n",
    "    Cual de las respuestas es correcta?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark', 3), ('datos', 2), ('guia', 2)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.textFile(\"Archivo.txt\")\\\n",
    "    .flatMap(lambda a: a.split()) \\\n",
    "    .map(lambda a: (a, 1))\\\n",
    "    .reduceByKey(lambda a, b: a+b)\\\n",
    "    .takeOrdered(3, key = lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Tenemos un RDD con números enteros llamado intergerListRDD al cual le aplicamos las siguientes acciones. -- integersListRDD.reduce(lambda a, b: a - b) integersListRDD.repartition(6).reduce(lambda a, b: a - b) -- Que podemos decir los resultados de la aplicar el reduce por un lado y de aplicar del repartition y el reduce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 6, 23, 5, 12, 42, 42, 6, 3, 344, 34, 5, 5, 5, 2, 4, 5, 67, 8, 9]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 3, 6, 23, 5, 12, 42, 42, 6 , 3 , 344 ,34 ,5 ,5 ,5 ,2 , 4, 5, 67,8 ,9]\n",
    "integersListRDD = sc.parallelize(a)\n",
    "integersListRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-159"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integersListRDD.reduce(lambda a, b: a - b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-159"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integersListRDD.repartition(6).reduce(lambda a, b: a - b) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Tengo un RDD con los siguientes campos: padron, apellido_nombre, fecha_nacimiento, fecha_ingreso, codigo_carrera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(92308, 'zarago jm', '1970-01-01', '2017-01-01', '10'),\n",
       " (92307, 'zarago jm', '1990-01-01', '2017-01-01', '10'),\n",
       " (92404, 'zarago jm', '1960-01-01', '2007-01-01', '12'),\n",
       " (95308, 'zarago jm', '1950-01-01', '2011-01-01', '11'),\n",
       " (93302, 'zarago jm', '1906-01-01', '2005-01-01', '10'),\n",
       " (92333, 'zarago6 jm', '1995-01-01', '1999-01-01', '11'),\n",
       " (98308, 'zarago7 jm', '1975-01-01', '2004-01-01', '10'),\n",
       " (97308, 'zarag6o jm', '1988-01-01', '2008-01-01', '12'),\n",
       " (88308, 'zarago6 jm', '1999-01-01', '2009-01-01', '10')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info = [\n",
    "    (92308, 'zarago jm', '1970-01-01', '2017-01-01', '10'),\n",
    "    (92307, 'zarago jm', '1990-01-01', '2017-01-01', '10'),\n",
    "    (92404, 'zarago jm', '1960-01-01', '2007-01-01', '12'),\n",
    "    (95308, 'zarago jm', '1950-01-01', '2011-01-01', '11'),\n",
    "    (93302, 'zarago jm', '1906-01-01', '2005-01-01', '10'),\n",
    "    (92333, 'zarago6 jm', '1995-01-01', '1999-01-01', '11'),\n",
    "    (98308, 'zarago7 jm', '1975-01-01', '2004-01-01', '10'),\n",
    "    (97308, 'zarag6o jm', '1988-01-01', '2008-01-01', '12'),\n",
    "    (88308, 'zarago6 jm', '1999-01-01', '2009-01-01', '10'),    \n",
    "]\n",
    "rdd = sc.parallelize(info)\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "obtiene la cantidad de alumnos por longitud de apellido y nombre para los alumnos que hayan ingresado despues del 2016-01-01 a la carrera 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(9, 2)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.filter(lambda row: row[4] == '10')\\\n",
    ".filter(lambda row: row[3] > '2016-01-01')\\\n",
    ".map(lambda row: (len(row[1]), 1)).reduceByKey(lambda a, b: a+b).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "obtiene la carrera con más alumnos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('12', 2)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.map(lambda row: (row[4], 1)).reduceByKey(lambda a, b: a+b).takeOrdered(1, key = lambda x: x[1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "obtiene los apellidos de los alumnos que hayan ingresado despues del 2016-01-01 a la carrera 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(9, 1)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.filter(lambda row: row[4] == '10').filter(lambda row: row[3] > '2016-01-01')\\\n",
    ".map(lambda row: (len(row[1]), 1)).reduceByKey(lambda a, b: a+b).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \tDado el siguiente código de pyspark e ignorando la definicion de pairRDD -- print pairRDD.groupByKey().mapValues(lambda x: sum(x)).collect() print pairRDD.reduceByKey(add).collect() -- Obtenemos la siguiente salida -- [('a', 3), ('b', 1)] [('a', 3), ('b', 1)] -- ¿Como debería estar definida pairRDD para obtener ese resultado?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('b', 1), ('a', 3)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairRDD = sc.parallelize([('a', 1), ('a', 1), ('a', 1), ('b', 1)]).repartition(12)\n",
    "pairRDD.groupByKey().mapValues(lambda x: sum(x)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('b', 1), ('a', 3)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairRDD.reduceByKey(lambda x,y:x+y).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 1), ('b', 3)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairRDD = sc.parallelize([('b', 1), ('b', 1), ('b', 1), ('a', 1)]).repartition(5)\n",
    "pairRDD.groupByKey().mapValues(lambda x: sum(x)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 1), ('b', 3)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairRDD.reduceByKey(lambda x,y:x+y).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'groupByKey'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-f0cb5ca2ecb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpairRDD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpairRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupByKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'groupByKey'"
     ]
    }
   ],
   "source": [
    "pairRDD = [('a', 1), ('a', 1), ('a', 1), ('b', 1)]\n",
    "pairRDD.groupByKey().mapValues(lambda x: sum(x)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'reduceByKey'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-5c13a19bd6cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpairRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduceByKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'reduceByKey'"
     ]
    }
   ],
   "source": [
    "pairRDD.reduceByKey(lambda x,y:x+y).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('b', 2), ('a', 3)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairRDD = sc.parallelize([('a', 1), ('a', 2), ('b', 2)])\n",
    "pairRDD.groupByKey().mapValues(lambda x: sum(x)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('b', 2), ('a', 3)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairRDD.reduceByKey(lambda x,y:x+y).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
